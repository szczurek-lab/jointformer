{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze molecule embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "\n",
    "from jointformer.configs.task import TaskConfig\n",
    "from jointformer.utils.datasets.auto import AutoDataset\n",
    "from jointformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from jointformer.configs.model import ModelConfig\n",
    "from jointformer.models.auto import AutoModel\n",
    "from jointformer.utils.properties.smiles.physchem import PhysChem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters setup\n",
    "\n",
    "Only modify below cell and run rest of the notebook. \n",
    "\n",
    "Alternatively, if you have `papermill` installed, you can run the notebook with:\n",
    "\n",
    "`papermill 01-embeddings-analysis.ipynb out_notebook.ipynb -f embedings_analysis_config.yml`\n",
    "\n",
    "from the command line, where `embedings_analysis_config.yml` stores the parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Provide parameters for running the script\n",
    "\n",
    "# Directory to save the outputs\n",
    "OUTPUT_DIR = 'embeddings_analysis_data/embeddings_analysis_output/'\n",
    "\n",
    "# Path to the task configuration file\n",
    "PATH_TO_TASK_CONFIG = '../../configs/tasks/guacamol/physchem/'\n",
    "\n",
    "# Path to vocabulary file\n",
    "PATH_TO_VOCAB = \"../../data/vocabularies/deepchem.txt\"\n",
    "\n",
    "# Path to model config\n",
    "PATH_TO_MODEL_CONFIG = '../../configs/models/jointformer/'\n",
    "\n",
    "# Path to the pre-trained model checkpoint\n",
    "PATH_TO_PRETRAINED_MODEL_CKPT = \"../../../../checkpoints/lm_physchem/ckpt.pt\"\n",
    "\n",
    "# Set list of properties to consider as labels\n",
    "PROPERTIES = ['MolLogP', 'TPSA', 'QED', 'MolWT']\n",
    "\n",
    "# If to take a sample of molecules for inference, can be None\n",
    "NUM_SAMPLES = 1000\n",
    "\n",
    "# Type of dimensionality reduction\n",
    "DIM_REDUCTION = 'pca'\n",
    "\n",
    "# Specify which dimensionalities of reduced embeddings to use for 2D plot\n",
    "# if \"first_two\" then first two dimensions are used. If \"top_correlated\", search for most correlated\n",
    "# dimensions with each property\n",
    "PERFORM_DIM_REDUCTION = True\n",
    "DIMENSIONS_FOR_VISUALIZATION = \"top_correlated\"\n",
    "CORR_TYPE = \"pearson\"\n",
    "\n",
    "FIGSIZE = (10, 7)\n",
    "SCATTERPLOT_KWARGS = {\n",
    "    'cmap': 'viridis'\n",
    "}\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(inputs, model, embedding_func, tokenizer, batch_size=32, **tokenizer_call_kwargs):\n",
    "    \"\"\"Compute embeddings in batches.\"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        inputs_batch = tokenizer(inputs[i:i + batch_size], **tokenizer_call_kwargs)\n",
    "        embeddings_batch = embedding_func(model, inputs_batch).detach()\n",
    "        embeddings.append(embeddings_batch)\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "def two_D_reduction(X, reducer=\"pca\", **reducer_kwargs):\n",
    "    \"\"\"\n",
    "    Performs dimensionality reduction on the input data.\n",
    "\n",
    "    Args:\n",
    "        X (array-like): Input data.\n",
    "        reducer (str, optional): The dimensionality reduction method to use. Options are 'pca' and 'tsne'. Defaults to 'pca'.\n",
    "        **reducer_kwargs: Additional keyword arguments to pass to the dimensionality reduction method.\n",
    "\n",
    "    Returns:\n",
    "        array-like: The reduced data.\n",
    "    \"\"\"\n",
    "    if reducer == \"pca\":\n",
    "        reducer = PCA(**reducer_kwargs)\n",
    "    elif reducer == \"tsne\":\n",
    "        reducer = TSNE(**reducer_kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown reducer: {reducer}\")\n",
    "\n",
    "    X_reduced = reducer.fit_transform(X)\n",
    "    return X_reduced\n",
    "\n",
    "def plot_2D_data_matplotlib(X_2d, ax=None, axis_titles=None, title=None, **scatter_kwargs):\n",
    "    \"\"\"\n",
    "    Plots the reduced data using matplotlib on the provided or a new axis.\n",
    "\n",
    "    Args:\n",
    "        X_2d (array-like): Reduced data.\n",
    "        ax (matplotlib.axes.Axes, optional): An existing axis to plot on. If None, a new figure and axis are created.\n",
    "        axis_aliases (list of str, optional): The aliases for the axes. Defaults to None.\n",
    "        **scatter_kwargs: Additional keyword arguments to pass to plt.scatter.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.axes.Axes: The matplotlib axes containing the plot.\n",
    "    \"\"\"\n",
    "    # If no axis is provided, create a new figure and axis\n",
    "    p = ax.scatter(X_2d[:, 0], X_2d[:, 1], **scatter_kwargs)\n",
    "    if \"c\" in scatter_kwargs:\n",
    "        plt.colorbar(p, ax=ax)\n",
    "    ax.set_xlabel(axis_titles[0] if axis_titles is not None else \"\")\n",
    "    ax.set_ylabel(axis_titles[1] if axis_titles is not None else \"\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    return ax\n",
    "    \n",
    "def get_most_correlated_dimensions(X, y, method=\"pearson\", absolute_vals=True):\n",
    "    \"\"\"\n",
    "    Get the two most correlated dimensions of X with a reference vector y w.r.t. Pearson or Spearman correlation.\n",
    "\n",
    "    Args:\n",
    "        X (array-like): Input data.\n",
    "        y (array-like): Reference vector.\n",
    "        method (str, optional): The correlation method to use. Options are 'pearson' and 'spearman'. Defaults to 'pearson'.\n",
    "        absolute_vals (bool, optional): Whether to consider the absolute values of the correlations. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The indices of the two most correlated dimensions.\n",
    "    \"\"\"\n",
    "    # Compute the correlation between each dimension of X and y\n",
    "    if method == \"pearson\":\n",
    "        correlations = np.array([pearsonr(X[:, i], y)[0] for i in range(X.shape[1])])\n",
    "    elif method == \"spearman\":\n",
    "        correlations = np.array([spearmanr(X[:, i], y)[0] for i in range(X.shape[1])])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown correlation method: {method}\")\n",
    "\n",
    "    # Get the indices of the two most correlated dimensions\n",
    "    if absolute_vals:\n",
    "        most_correlated_dims = np.argsort(np.abs(correlations))[::-1][:2]\n",
    "    else:\n",
    "        most_correlated_dims = np.argsort(correlations)[::-1][:2]\n",
    "\n",
    "    return most_correlated_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = TaskConfig.from_config_file(PATH_TO_TASK_CONFIG)\n",
    "task_config.path_to_vocabulary = PATH_TO_VOCAB\n",
    "\n",
    "dataset = AutoDataset.from_config(task_config, split='test')\n",
    "tokenizer = AutoTokenizer.from_config(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of property names\n",
    "phys_chem = PhysChem()\n",
    "property_names = phys_chem.descriptor_list\n",
    "\n",
    "# Get indexes of the properties to consider\n",
    "property_idx_dict = {prop: list(map(lambda x: x.lower(), property_names)).index(prop.lower()) for prop in PROPERTIES}\n",
    "\n",
    "# Get indexes of the properties to consider\n",
    "props, idxs = [], []\n",
    "for prop in PROPERTIES:\n",
    "    if prop.lower() not in list(map(lambda x: x.lower(), property_names)):\n",
    "        raise ValueError(f\"Property {prop} not found in the list of available properties.\")\n",
    "    idx = list(map(lambda x: x.lower(), property_names)).index(prop.lower()) \n",
    "    props.append(prop)\n",
    "    idxs.append(idx)\n",
    "    print(f\"User provided property name {prop} mapped to property name {property_names[idx]} with index {idx}.\")\n",
    "\n",
    "# Extract SMILES\n",
    "molecules_list = dataset.data\n",
    "\n",
    "# Extract proper labels corresponding to properties of choice\n",
    "labels = dataset.target[:, 0, idxs]\n",
    "labels_df = pd.DataFrame(labels, columns=props)\n",
    "\n",
    "# Make sure you have correct labels data\n",
    "for prop in PROPERTIES:\n",
    "    df_values = labels_df[prop].values\n",
    "    idx = list(map(lambda x: x.lower(), property_names)).index(prop.lower())\n",
    "    assert property_names[idx].lower() == prop.lower(), f\"Property {prop} not found in the list of available properties.\"\n",
    "    assert np.allclose(df_values, dataset.target[:, 0, idx]), f\"Property {prop} values do not match.\"\n",
    "\n",
    "# Optionally, take sample of the data\n",
    "if NUM_SAMPLES is not None:\n",
    "    # Sample indices\n",
    "    np.random.seed(SEED)\n",
    "    sample_indices = np.random.choice(len(molecules_list), NUM_SAMPLES, replace=False)\n",
    "    molecules_list = [molecules_list[i] for i in sample_indices]\n",
    "    labels_df = labels_df.iloc[sample_indices]\n",
    "\n",
    "assert len(molecules_list) == len(labels_df), \"Number of molecules and labels do not match.\"\n",
    "\n",
    "print()\n",
    "print(f\"Number of molecules to infer: {len(molecules_list)}\")\n",
    "print(f\"Number of properties: {len(labels_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig.from_config_file(PATH_TO_MODEL_CONFIG)\n",
    "model = AutoModel.from_config(model_config)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load weights\n",
    "model.load_pretrained(PATH_TO_PRETRAINED_MODEL_CKPT)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D visualizations of embeddings for a set of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an embeddings function\n",
    "embeddings_func = lambda model, inputs: model(**inputs)[\"embeddings\"].mean(1)\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = compute_embeddings(molecules_list, model, embeddings_func, tokenizer, batch_size=2)\n",
    "embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "# Reduce dimensionality\n",
    "if PERFORM_DIM_REDUCTION:\n",
    "    reduced_embeddings = two_D_reduction(embeddings, reducer=DIM_REDUCTION, n_components=embeddings.shape[1],\n",
    "                                         random_state=SEED)\n",
    "else:\n",
    "    reduced_embeddings = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings - multiple targets\n",
    "if OUTPUT_DIR is not None and not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "NUM_COLS = 2\n",
    "NUM_ROWS = int(np.ceil(len(PROPERTIES) / NUM_COLS))\n",
    "\n",
    "fig, axes = plt.subplots(NUM_ROWS, NUM_COLS, figsize=FIGSIZE)\n",
    "\n",
    "if DIM_REDUCTION == \"pca\":\n",
    "    axis_alias = 'PCA'\n",
    "elif DIM_REDUCTION == \"tsne\":\n",
    "    axis_alias = 'tSNE'\n",
    "\n",
    "for i, prop in enumerate(PROPERTIES):\n",
    "    # Establish which dimensions to use for visualization\n",
    "    if DIMENSIONS_FOR_VISUALIZATION == \"first_two\":\n",
    "        current_2d_data = reduced_embeddings[:, :2]\n",
    "        ax1_alias = f\"{axis_alias} 1\"\n",
    "        ax2_alias = f\"{axis_alias} 2\"\n",
    "    elif DIMENSIONS_FOR_VISUALIZATION == \"top_correlated\":\n",
    "        most_correlated_dims = get_most_correlated_dimensions(reduced_embeddings, labels_df[prop].values, method=CORR_TYPE)\n",
    "        current_2d_data = reduced_embeddings[:, most_correlated_dims]\n",
    "        ax1_alias = f\"{axis_alias} {most_correlated_dims[0] + 1}\"\n",
    "        ax2_alias = f\"{axis_alias} {most_correlated_dims[1] + 1}\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown value for DIMENSIONS_FOR_VISUALIZATION: {DIMENSIONS_FOR_VISUALIZATION}\")\n",
    "\n",
    "    # Plot the data\n",
    "    ax = axes[i // NUM_COLS, i % NUM_COLS]\n",
    "    plot_2D_data_matplotlib(current_2d_data, ax=ax, c=labels_df[prop].values, \n",
    "            title=f\"Property: {prop}\",\n",
    "            **SCATTERPLOT_KWARGS)\n",
    "    ax.set_xlabel(ax1_alias)\n",
    "    ax.set_ylabel(ax2_alias)\n",
    "   \n",
    "    # Add colorbar title\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label(prop)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "if OUTPUT_DIR is not None:\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"embeddings_{DIM_REDUCTION}_{DIMENSIONS_FOR_VISUALIZATION}.pdf\"))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
