{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular cliffs analysis\n",
    "\n",
    "Test the usage of Jointformer embeddings on bioactivity prediction task considering bioactivity cliffs.\n",
    "\n",
    "This notebook utilizes MoleculeACE package: https://github.com/molML/MoleculeACE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-12 07:25:17.644901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-12 07:25:17.673640: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-12 07:25:17.682142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-12 07:25:17.704082: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-12 07:25:19.357277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from MoleculeACE import Data, Descriptors, get_benchmark_config, calc_rmse, calc_cliff_rmse\n",
    "from MoleculeACE import SVM as MoleculeACE_SVM\n",
    "from MoleculeACE import KNN as MoleculeACE_KNN\n",
    "\n",
    "from jointformer.configs.dataset import DatasetConfig\n",
    "from jointformer.configs.tokenizer import TokenizerConfig\n",
    "from jointformer.utils.datasets.auto import AutoDataset\n",
    "from jointformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from jointformer.configs.model import ModelConfig\n",
    "from jointformer.models.auto import AutoModel\n",
    "from jointformer.utils.properties.smiles.physchem import PhysChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(inputs, model, embedding_func, tokenizer, batch_size=32, **tokenizer_call_kwargs):\n",
    "    \"\"\"Compute embeddings in batches.\"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        inputs_batch = tokenizer(inputs[i:i + batch_size], **tokenizer_call_kwargs)\n",
    "        embeddings_batch = embedding_func(model, inputs_batch).detach()\n",
    "        embeddings.append(embeddings_batch)\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"Evaluate regression predictions.\"\"\"\n",
    "    rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
    "    pearson = pearsonr(y_true, y_pred)[0]\n",
    "    spearman = spearmanr(y_true, y_pred)[0]\n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"pearson\": pearson,\n",
    "        \"spearman\": spearman,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MoleculeACE datasets info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ChEMBL ID</th>\n",
       "      <th>Target name</th>\n",
       "      <th>Abbriviation</th>\n",
       "      <th>Type</th>\n",
       "      <th>Receptor Class</th>\n",
       "      <th>Compounds</th>\n",
       "      <th>Cliff compounds</th>\n",
       "      <th>Percentage cliffs</th>\n",
       "      <th>Train compounds</th>\n",
       "      <th>Train cliff compounds</th>\n",
       "      <th>Percentage train cliffs</th>\n",
       "      <th>Test compounds</th>\n",
       "      <th>Test cliff compounds</th>\n",
       "      <th>Percentage test cliffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>CHEMBL1871</td>\n",
       "      <td>Androgen Receptor</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ki</td>\n",
       "      <td>NR</td>\n",
       "      <td>659</td>\n",
       "      <td>157</td>\n",
       "      <td>24</td>\n",
       "      <td>525</td>\n",
       "      <td>126</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL218_EC50</td>\n",
       "      <td>CHEMBL218</td>\n",
       "      <td>Cannabinoid receptor 1</td>\n",
       "      <td>CB1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>GPCR</td>\n",
       "      <td>1031</td>\n",
       "      <td>367</td>\n",
       "      <td>36</td>\n",
       "      <td>823</td>\n",
       "      <td>292</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "      <td>75</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL244_Ki</td>\n",
       "      <td>CHEMBL244</td>\n",
       "      <td>Coagulation factor X</td>\n",
       "      <td>FX</td>\n",
       "      <td>Ki</td>\n",
       "      <td>Protease</td>\n",
       "      <td>3097</td>\n",
       "      <td>1350</td>\n",
       "      <td>44</td>\n",
       "      <td>2476</td>\n",
       "      <td>1080</td>\n",
       "      <td>44</td>\n",
       "      <td>621</td>\n",
       "      <td>270</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL236_Ki</td>\n",
       "      <td>CHEMBL236</td>\n",
       "      <td>Delta opioid receptor</td>\n",
       "      <td>DOR</td>\n",
       "      <td>Ki</td>\n",
       "      <td>GPCR</td>\n",
       "      <td>2598</td>\n",
       "      <td>965</td>\n",
       "      <td>37</td>\n",
       "      <td>2077</td>\n",
       "      <td>772</td>\n",
       "      <td>37</td>\n",
       "      <td>521</td>\n",
       "      <td>193</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL234_Ki</td>\n",
       "      <td>CHEMBL234</td>\n",
       "      <td>Dopamine D3 receptor</td>\n",
       "      <td>D3R</td>\n",
       "      <td>Ki</td>\n",
       "      <td>GPCR</td>\n",
       "      <td>3657</td>\n",
       "      <td>1441</td>\n",
       "      <td>39</td>\n",
       "      <td>2923</td>\n",
       "      <td>1150</td>\n",
       "      <td>39</td>\n",
       "      <td>734</td>\n",
       "      <td>291</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dataset   ChEMBL ID             Target name Abbriviation  Type  \\\n",
       "0   CHEMBL1871_Ki  CHEMBL1871       Androgen Receptor           AR    Ki   \n",
       "1  CHEMBL218_EC50   CHEMBL218  Cannabinoid receptor 1          CB1  EC50   \n",
       "2    CHEMBL244_Ki   CHEMBL244    Coagulation factor X           FX    Ki   \n",
       "3    CHEMBL236_Ki   CHEMBL236   Delta opioid receptor          DOR    Ki   \n",
       "4    CHEMBL234_Ki   CHEMBL234    Dopamine D3 receptor          D3R    Ki   \n",
       "\n",
       "  Receptor Class  Compounds  Cliff compounds  Percentage cliffs  \\\n",
       "0             NR        659              157                 24   \n",
       "1           GPCR       1031              367                 36   \n",
       "2       Protease       3097             1350                 44   \n",
       "3           GPCR       2598              965                 37   \n",
       "4           GPCR       3657             1441                 39   \n",
       "\n",
       "   Train compounds  Train cliff compounds  Percentage train cliffs  \\\n",
       "0              525                    126                       24   \n",
       "1              823                    292                       35   \n",
       "2             2476                   1080                       44   \n",
       "3             2077                    772                       37   \n",
       "4             2923                   1150                       39   \n",
       "\n",
       "   Test compounds  Test cliff compounds  Percentage test cliffs  \n",
       "0             134                    31                      23  \n",
       "1             208                    75                      36  \n",
       "2             621                   270                      43  \n",
       "3             521                   193                      37  \n",
       "4             734                   291                      40  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all datasets from the MoleculeACE package\n",
    "datasets_list_df = pd.read_csv('https://github.com/molML/MoleculeACE/blob/main/MoleculeACE/Data/benchmark_data/metadata/datasets.csv?raw=true')\n",
    "\n",
    "print(datasets_list_df.shape)\n",
    "datasets_list_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple datasets modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Jointformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_dict = {\n",
    "        \"path_to_tokenizer\": '../../../../checkpoints/jointformer/separate_task_token/configs/tokenizers/smiles_separate_task_token',\n",
    "        \"path_to_model_config\": '../../../../checkpoints/jointformer/separate_task_token/configs/models/jointformer_separate_task_token',\n",
    "        \"path_to_vocab\": \"../../data/vocabularies/deepchem.txt\",\n",
    "        \"path_to_model_checkpoint\": \"../../../../checkpoints/jointformer/separate_task_token/ckpt.pt\"\n",
    "    }\n",
    "\n",
    "# Get tokenizer\n",
    "tokenizer_config = TokenizerConfig.from_config_file(model_config_dict[\"path_to_tokenizer\"])\n",
    "tokenizer_config.path_to_vocabulary = model_configs_dict[\"path_to_vocab\"]\n",
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)\n",
    "\n",
    "model_config = ModelConfig.from_config_file(model_config_dict[\"path_to_model_config\"])\n",
    "jointformer = AutoModel.from_config(model_config)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load model checkpoint on cpu\n",
    "jointformer.eval()\n",
    "jointformer.to(device)    \n",
    "\n",
    "jointformer.load_pretrained(model_config_dict[\"path_to_model_checkpoint\"])\n",
    "\n",
    "smiles_encoder = jointformer.to_smiles_encoder(tokenizer, batch_size=2, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get model\n",
    "#     model_config = ModelConfig.from_config_file(model_configs_dict[model_alias][\"path_to_model_config\"])\n",
    "#     model = AutoModel.from_config(model_config)\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#     # Load model checkpoint on cpu\n",
    "#     model.eval()\n",
    "#     model.to(device)    \n",
    "\n",
    "#     if model_alias != \"ChemBERTa\":\n",
    "#         try:\n",
    "#             model.load_pretrained(model_configs_dict[model_alias][\"path_to_model_checkpoint\"])\n",
    "#         except RuntimeError:\n",
    "#             model.load_pretrained(model_configs_dict[model_alias][\"path_to_model_checkpoint\"], map_location='cpu')\n",
    "\n",
    "#     # Get embeddings\n",
    "#     print(f\"Computing embeddings for model {model_alias}...\")\n",
    "\n",
    "#     smiles_encoder = model.to_smiles_encoder(tokenizer, batch_size=2, device=\"cpu\")\n",
    "#     embeddings = smiles_encoder.encode(molecules_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over datasets and compare ML models with Jointformer embeddings with best model and representations from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hparams grid for traditional ML models - same grids as in MoleculeACE paper\n",
    "per_model_hyperparameters_grid = {\n",
    "    \"knn\": {\n",
    "        \"n_neighbors\": [1, 3, 11, 21],\n",
    "        \"metric\": [\"cosine\", \"euclidean\"]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"C\": [1, 10, 100, 1000, 10000],\n",
    "        \"gamma\": [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding samples:   0%|          | 1/263 [00:00<00:40,  6.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding samples:  82%|████████▏ | 215/263 [00:12<00:02, 18.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  83%|████████▎ | 217/263 [00:12<00:02, 18.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  83%|████████▎ | 219/263 [00:12<00:02, 17.21it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  84%|████████▍ | 221/263 [00:12<00:02, 16.38it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  85%|████████▍ | 223/263 [00:13<00:02, 15.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  86%|████████▌ | 225/263 [00:13<00:02, 15.66it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  86%|████████▋ | 227/263 [00:13<00:02, 15.73it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 263/263 [00:15<00:00, 17.13it/s]\n",
      "Encoding samples:  84%|████████▎ | 56/67 [00:03<00:00, 14.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  87%|████████▋ | 58/67 [00:03<00:00, 14.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 67/67 [00:04<00:00, 16.03it/s]\n",
      "Encoding samples:  56%|█████▌    | 230/412 [00:14<00:12, 14.29it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 412/412 [00:25<00:00, 16.05it/s]\n",
      "Encoding samples: 100%|██████████| 104/104 [00:05<00:00, 17.50it/s]\n",
      "Encoding samples:  74%|███████▍  | 922/1238 [00:57<00:19, 16.48it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  98%|█████████▊| 1210/1238 [01:14<00:01, 15.31it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|█████████▉| 1236/1238 [01:15<00:00, 15.98it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 1238/1238 [01:15<00:00, 16.33it/s]\n",
      "Encoding samples:  99%|█████████▉| 308/311 [00:17<00:00, 18.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 311/311 [00:18<00:00, 17.16it/s]\n",
      "Encoding samples:   1%|          | 6/1039 [00:00<01:12, 14.27it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   1%|          | 10/1039 [00:00<01:11, 14.39it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   1%|▏         | 14/1039 [00:00<01:08, 14.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   2%|▏         | 18/1039 [00:01<01:06, 15.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   2%|▏         | 24/1039 [00:01<01:10, 14.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 26/1039 [00:01<01:11, 14.26it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 30/1039 [00:02<01:17, 13.06it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 32/1039 [00:02<01:16, 13.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 34/1039 [00:02<01:13, 13.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   6%|▌         | 64/1039 [00:04<00:52, 18.62it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   6%|▋         | 66/1039 [00:04<00:52, 18.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 68/1039 [00:04<00:52, 18.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 70/1039 [00:04<00:51, 18.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 72/1039 [00:04<00:51, 18.68it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 76/1039 [00:04<00:53, 17.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   8%|▊         | 78/1039 [00:04<00:52, 18.15it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  13%|█▎        | 132/1039 [00:07<00:49, 18.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  13%|█▎        | 140/1039 [00:08<00:48, 18.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  16%|█▌        | 162/1039 [00:09<00:53, 16.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 198/1039 [00:12<01:19, 10.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 200/1039 [00:12<01:15, 11.10it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 202/1039 [00:12<01:10, 11.87it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  20%|█▉        | 204/1039 [00:12<01:07, 12.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  21%|██        | 216/1039 [00:13<00:58, 13.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  27%|██▋       | 280/1039 [00:18<00:49, 15.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  27%|██▋       | 282/1039 [00:18<00:47, 15.87it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  33%|███▎      | 338/1039 [00:21<00:40, 17.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  38%|███▊      | 396/1039 [00:24<00:35, 18.07it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  38%|███▊      | 398/1039 [00:24<00:35, 18.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  48%|████▊     | 500/1039 [00:30<00:29, 18.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  50%|████▉     | 518/1039 [00:31<00:28, 18.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  50%|█████     | 520/1039 [00:31<00:29, 17.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  54%|█████▍    | 566/1039 [00:34<00:26, 18.01it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  55%|█████▍    | 568/1039 [00:34<00:26, 17.78it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  60%|██████    | 628/1039 [00:37<00:22, 18.07it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  61%|██████    | 630/1039 [00:37<00:22, 18.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  61%|██████    | 632/1039 [00:37<00:22, 18.21it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  63%|██████▎   | 654/1039 [00:39<00:23, 16.20it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  63%|██████▎   | 656/1039 [00:39<00:23, 16.32it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  66%|██████▌   | 686/1039 [00:40<00:20, 17.45it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  66%|██████▌   | 688/1039 [00:41<00:20, 17.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  69%|██████▉   | 720/1039 [00:42<00:18, 17.21it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  69%|██████▉   | 722/1039 [00:43<00:19, 16.68it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  70%|██████▉   | 724/1039 [00:43<00:19, 16.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  71%|███████   | 740/1039 [00:44<00:16, 17.75it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  71%|███████▏  | 742/1039 [00:44<00:16, 17.85it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  72%|███████▏  | 746/1039 [00:44<00:15, 18.34it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 780/1039 [00:46<00:14, 18.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 782/1039 [00:46<00:13, 18.36it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 784/1039 [00:46<00:14, 17.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 786/1039 [00:46<00:15, 16.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 790/1039 [00:47<00:16, 14.85it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 792/1039 [00:47<00:16, 15.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▋  | 794/1039 [00:47<00:15, 15.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  77%|███████▋  | 804/1039 [00:47<00:12, 18.38it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  78%|███████▊  | 806/1039 [00:47<00:12, 18.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  78%|███████▊  | 810/1039 [00:48<00:12, 18.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  79%|███████▉  | 824/1039 [00:48<00:11, 18.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 976/1039 [00:58<00:04, 12.85it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 978/1039 [00:58<00:05, 12.15it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 980/1039 [00:58<00:04, 12.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  96%|█████████▌| 1000/1039 [01:00<00:03, 12.68it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  96%|█████████▋| 1002/1039 [01:00<00:02, 12.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 1039/1039 [01:03<00:00, 16.47it/s]\n",
      "Encoding samples:   0%|          | 0/261 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   2%|▏         | 4/261 [00:00<00:15, 16.61it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   5%|▌         | 14/261 [00:00<00:14, 17.26it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   6%|▌         | 16/261 [00:00<00:13, 17.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  18%|█▊        | 46/261 [00:02<00:14, 14.89it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  18%|█▊        | 48/261 [00:02<00:13, 15.35it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 50/261 [00:03<00:13, 15.73it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  25%|██▍       | 64/261 [00:03<00:10, 18.04it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  25%|██▌       | 66/261 [00:03<00:10, 17.90it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  31%|███       | 80/261 [00:04<00:10, 17.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  47%|████▋     | 122/261 [00:07<00:10, 13.80it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  50%|████▉     | 130/261 [00:08<00:09, 14.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  59%|█████▉    | 154/261 [00:10<00:07, 13.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  63%|██████▎   | 164/261 [00:11<00:07, 13.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  64%|██████▍   | 168/261 [00:11<00:06, 13.76it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  67%|██████▋   | 176/261 [00:11<00:06, 13.61it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  68%|██████▊   | 178/261 [00:12<00:05, 14.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  69%|██████▉   | 180/261 [00:12<00:05, 15.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  71%|███████▏  | 186/261 [00:12<00:04, 16.80it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 196/261 [00:13<00:03, 16.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 198/261 [00:13<00:03, 16.64it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  77%|███████▋  | 202/261 [00:13<00:03, 15.89it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  78%|███████▊  | 204/261 [00:13<00:03, 15.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  80%|███████▉  | 208/261 [00:13<00:03, 15.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  93%|█████████▎| 242/261 [00:15<00:01, 18.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  95%|█████████▌| 248/261 [00:16<00:00, 17.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 261/261 [00:16<00:00, 15.55it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Grid search\u001b[39;00m\n\u001b[1;32m     23\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, per_model_hyperparameters_grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m\"\u001b[39m], scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_jointformer_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test_jointformer_embeddings)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize results \n",
    "results = {\n",
    "    \"dataset\": [],\n",
    "    \"model\": [],\n",
    "    \"test_rmse\": [],\n",
    "    \"test_cliff_rmse\": [],\n",
    "}\n",
    "\n",
    "# Iterate over all datasets\n",
    "for dataset in datasets_list_df[\"Dataset\"].unique():\n",
    "    # Load data\n",
    "    raw_data = Data(dataset)\n",
    "\n",
    "    # Compute embeddings\n",
    "    X_train_jointformer_embeddings = smiles_encoder.encode(raw_data.smiles_train)\n",
    "\n",
    "    X_test_jointformer_embeddings = smiles_encoder.encode(raw_data.smiles_test)\n",
    "\n",
    "    ### Model with svm and jointformer embeddings\n",
    "    model = SVR(kernel=\"rbf\")\n",
    "\n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(model, per_model_hyperparameters_grid[\"svm\"], scoring=\"neg_mean_squared_error\", n_jobs=2, cv=5)\n",
    "    grid_search.fit(X_train_jointformer_embeddings, raw_data.y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test_jointformer_embeddings)\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"svm_jointformer\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "    ### Model with knn and jointformer embeddings\n",
    "    model = KNeighborsRegressor()\n",
    "\n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(model, per_model_hyperparameters_grid[\"knn\"], scoring=\"neg_mean_squared_error\", n_jobs=2, cv=5)\n",
    "    grid_search.fit(X_train_jointformer_embeddings, raw_data.y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test_jointformer_embeddings)\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"knn_jointformer\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "    ### Model from the MoleculeACE package - SVM with ECFP fingerprints\n",
    "    algorithm = MoleculeACE_SVM\n",
    "    \n",
    "    # Get a featurizer\n",
    "    descriptor = Descriptors.ECFP\n",
    "    # Featurize the data\n",
    "    raw_data(descriptor)\n",
    "\n",
    "    # Get the already optimized hyperparameters\n",
    "    hyperparameters = get_benchmark_config(dataset, algorithm, descriptor)\n",
    "\n",
    "    # Train and evaluate\n",
    "    model = algorithm(**hyperparameters)\n",
    "    model.train(raw_data.x_train, raw_data.y_train)\n",
    "    y_pred = model.predict(raw_data.x_test)\n",
    "\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"svm_ecfp\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "    ### Model from the MoleculeACE package - KNN with ECFP fingerprints\n",
    "    algorithm = MoleculeACE_KNN\n",
    "    \n",
    "    # Get a featurizer\n",
    "    descriptor = Descriptors.ECFP\n",
    "    # Featurize the data\n",
    "    raw_data(descriptor)\n",
    "\n",
    "    # Get the already optimized hyperparameters\n",
    "    hyperparameters = get_benchmark_config(dataset, algorithm, descriptor)\n",
    "\n",
    "    # Train and evaluate\n",
    "    model = algorithm(**hyperparameters)\n",
    "    model.train(raw_data.x_train, raw_data.y_train)\n",
    "    y_pred = model.predict(raw_data.x_test)\n",
    "\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"knn_ecfp\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_cliff_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>svm_jointformer</td>\n",
       "      <td>0.812010</td>\n",
       "      <td>1.036033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>knn_jointformer</td>\n",
       "      <td>0.847621</td>\n",
       "      <td>1.165791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.664931</td>\n",
       "      <td>0.873356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>knn_ecfp</td>\n",
       "      <td>0.649790</td>\n",
       "      <td>0.817006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL218_EC50</td>\n",
       "      <td>svm_jointformer</td>\n",
       "      <td>0.761406</td>\n",
       "      <td>0.819545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset            model  test_rmse  test_cliff_rmse\n",
       "0   CHEMBL1871_Ki  svm_jointformer   0.812010         1.036033\n",
       "1   CHEMBL1871_Ki  knn_jointformer   0.847621         1.165791\n",
       "2   CHEMBL1871_Ki         svm_ecfp   0.664931         0.873356\n",
       "3   CHEMBL1871_Ki         knn_ecfp   0.649790         0.817006\n",
       "4  CHEMBL218_EC50  svm_jointformer   0.761406         0.819545"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results_df.shape)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_rmse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_cliff_rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn_ecfp</th>\n",
       "      <td>0.728975</td>\n",
       "      <td>0.095928</td>\n",
       "      <td>0.838777</td>\n",
       "      <td>0.093639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_jointformer</th>\n",
       "      <td>0.884553</td>\n",
       "      <td>0.122473</td>\n",
       "      <td>0.928047</td>\n",
       "      <td>0.123543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_ecfp</th>\n",
       "      <td>0.671198</td>\n",
       "      <td>0.079625</td>\n",
       "      <td>0.751129</td>\n",
       "      <td>0.095433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_jointformer</th>\n",
       "      <td>0.784181</td>\n",
       "      <td>0.110780</td>\n",
       "      <td>0.864499</td>\n",
       "      <td>0.114079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                test_rmse           test_cliff_rmse          \n",
       "                     mean       std            mean       std\n",
       "model                                                        \n",
       "knn_ecfp         0.728975  0.095928        0.838777  0.093639\n",
       "knn_jointformer  0.884553  0.122473        0.928047  0.123543\n",
       "svm_ecfp         0.671198  0.079625        0.751129  0.095433\n",
       "svm_jointformer  0.784181  0.110780        0.864499  0.114079"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate results over models\n",
    "results_agg_df = results_df.groupby(\"model\").agg({\n",
    "    \"test_rmse\": [\"mean\", \"std\"],\n",
    "    \"test_cliff_rmse\": [\"mean\", \"std\"],\n",
    "})\n",
    "results_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117032/753014347.py:16: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=results_df, x=\"model\", y=\"test_rmse\", ax=ax[0], palette=p)\n",
      "/tmp/ipykernel_117032/753014347.py:23: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=results_df, x=\"model\", y=\"test_cliff_rmse\", ax=ax[1], palette=p)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot of the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Define your custom palette\n",
    "p = {\n",
    "    \"svm_jointformer\": \"skyblue\",\n",
    "    \"knn_jointformer\": \"skyblue\",\n",
    "    \"svm_ecfp\": \"lightcoral\",\n",
    "    \"knn_ecfp\": \"lightcoral\",\n",
    "\n",
    "}\n",
    "\n",
    "sns.boxplot(data=results_df, x=\"model\", y=\"test_rmse\", ax=ax[0], palette=p)\n",
    "ax[0].set_title(\"Bioactivity prediction RMSE - all\")\n",
    "ax[0].set_ylabel(\"Test RMSE\")\n",
    "ax[0].set_xlabel(\"Model\")\n",
    "# Same scale on y-axis\n",
    "ax[0].set_ylim(0, 2)\n",
    "\n",
    "sns.boxplot(data=results_df, x=\"model\", y=\"test_cliff_rmse\", ax=ax[1], palette=p)\n",
    "ax[1].set_title(\"Bioactivity prediction RMSE - activity cliffs\")\n",
    "ax[1].set_ylabel(\"Test cliff RMSE\")\n",
    "ax[1].set_xlabel(\"Model\")\n",
    "# Same scale on y-axis\n",
    "ax[1].set_ylim(0, 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for every model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "model_configs_dict = {\n",
    "    # \"Unimol\": {\n",
    "    #     \"path_to_tokenizer\": None,\n",
    "    #     \"path_to_model_config\": '../../configs/models/unimol',\n",
    "    #     \"path_to_model_checkpoint\": \"../../../../checkpoints/unimol/ckpt.pt\"\n",
    "    # },\n",
    "\n",
    "    \"Jointformer\": {\n",
    "        \"path_to_tokenizer\": '../../../../checkpoints/jointformer/separate_task_token/configs/tokenizers/smiles_separate_task_token',\n",
    "        \"path_to_model_config\": '../../../../checkpoints/jointformer/separate_task_token/configs/models/jointformer_separate_task_token',\n",
    "        \"path_to_vocab\": \"../../data/vocabularies/deepchem.txt\",\n",
    "        \"path_to_model_checkpoint\": \"../../../../checkpoints/jointformer/separate_task_token/ckpt.pt\"\n",
    "    },\n",
    "\n",
    "    \"ChemBERTa\": {\n",
    "        \"path_to_tokenizer\": \"../../configs/tokenizers/chemberta\",\n",
    "        \"path_to_model_config\": '../../configs/models/chemberta_for_regression',\n",
    "        \"path_to_model_checkpoint\": \"DeepChem/ChemBERTa-77M-MTR\"\n",
    "    },\n",
    "\n",
    "    \"MolGPT\": {\n",
    "        \"path_to_tokenizer\": None,\n",
    "        \"path_to_model_config\": '../../configs/models/molgpt',\n",
    "        \"path_to_model_checkpoint\": \"../../../../checkpoints/molgpt/ckpt.pt\"\n",
    "\n",
    "    },\n",
    "\n",
    "    \"MoLeR\": {\n",
    "        \"path_to_tokenizer\": None,\n",
    "        \"path_to_model_config\": '../../configs/models/moler',\n",
    "        \"path_to_model_checkpoint\": \"../../../../checkpoints/moler/ckpt.pkl\"\n",
    "    },\n",
    "    \n",
    "    # \"RegressionTransformer\": {\n",
    "    #     \"path_to_tokenizer\": None,\n",
    "    #     \"path_to_model_config\": '../../configs/models/regression_transformer',\n",
    "    #     \"path_to_model_checkpoint\": \"../../../../checkpoints/regression_transformer/logp_synthesizability/logp_and_synthesizability/pytorch_model.bin\"\n",
    "    # }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hparams grid for traditional ML models - same grids as in MoleculeACE paper\n",
    "per_model_hyperparameters_grid = {\n",
    "    \"knn\": {\n",
    "        \"n_neighbors\": [1, 3, 11, 21],\n",
    "        \"metric\": [\"cosine\", \"euclidean\"]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"C\": [1, 10, 100, 1000, 10000],\n",
    "        \"gamma\": [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model Jointformer...\n",
      "Computing embeddings for model Jointformer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding samples:  82%|████████▏ | 216/263 [00:15<00:03, 14.07it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  83%|████████▎ | 218/263 [00:15<00:03, 13.13it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  84%|████████▎ | 220/263 [00:15<00:03, 12.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  84%|████████▍ | 222/263 [00:15<00:03, 12.22it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  85%|████████▌ | 224/263 [00:15<00:03, 12.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  86%|████████▌ | 226/263 [00:15<00:02, 12.39it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 263/263 [00:18<00:00, 14.33it/s]\n",
      "Encoding samples:  84%|████████▎ | 56/67 [00:03<00:00, 16.35it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  87%|████████▋ | 58/67 [00:03<00:00, 14.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 67/67 [00:04<00:00, 15.39it/s]\n",
      "Encoding samples:  56%|█████▌    | 229/412 [00:15<00:12, 15.13it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  56%|█████▌    | 231/412 [00:15<00:11, 15.11it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 412/412 [00:27<00:00, 14.84it/s]\n",
      "Encoding samples: 100%|██████████| 104/104 [00:07<00:00, 14.47it/s]\n",
      "Encoding samples:  74%|███████▍  | 921/1238 [01:00<00:22, 13.82it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▍  | 923/1238 [01:00<00:23, 13.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  98%|█████████▊| 1209/1238 [01:19<00:01, 16.26it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|█████████▉| 1235/1238 [01:21<00:00, 15.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 1238/1238 [01:21<00:00, 15.18it/s]\n",
      "Encoding samples:  99%|█████████▉| 308/311 [00:20<00:00, 16.30it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 311/311 [00:20<00:00, 14.88it/s]\n",
      "Encoding samples:   1%|          | 6/1039 [00:00<01:14, 13.89it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   1%|          | 10/1039 [00:00<01:09, 14.76it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   1%|▏         | 14/1039 [00:00<01:06, 15.34it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   2%|▏         | 18/1039 [00:01<01:03, 16.05it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   2%|▏         | 24/1039 [00:01<01:07, 14.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 26/1039 [00:01<01:14, 13.65it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 30/1039 [00:02<01:19, 12.69it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 32/1039 [00:02<01:20, 12.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   3%|▎         | 34/1039 [00:02<01:17, 12.92it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   6%|▌         | 64/1039 [00:04<01:03, 15.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   6%|▋         | 66/1039 [00:04<01:08, 14.18it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 68/1039 [00:04<01:08, 14.18it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 70/1039 [00:05<01:07, 14.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 72/1039 [00:05<01:07, 14.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   7%|▋         | 76/1039 [00:05<01:11, 13.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   8%|▊         | 78/1039 [00:05<01:10, 13.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  13%|█▎        | 132/1039 [00:09<00:50, 17.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  13%|█▎        | 140/1039 [00:09<00:54, 16.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  16%|█▌        | 162/1039 [00:11<00:59, 14.63it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 198/1039 [00:13<01:01, 13.64it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 200/1039 [00:13<01:03, 13.30it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 202/1039 [00:13<01:02, 13.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  20%|█▉        | 204/1039 [00:14<01:04, 12.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  21%|██        | 216/1039 [00:14<00:59, 13.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  27%|██▋       | 280/1039 [00:19<00:55, 13.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  27%|██▋       | 282/1039 [00:19<00:55, 13.69it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  33%|███▎      | 338/1039 [00:23<00:45, 15.33it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  38%|███▊      | 396/1039 [00:26<00:44, 14.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  38%|███▊      | 398/1039 [00:26<00:43, 14.62it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  48%|████▊     | 500/1039 [00:33<00:36, 14.76it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  50%|████▉     | 518/1039 [00:34<00:32, 16.22it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  50%|█████     | 520/1039 [00:35<00:33, 15.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  54%|█████▍    | 566/1039 [00:38<00:30, 15.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  55%|█████▍    | 568/1039 [00:38<00:30, 15.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  60%|██████    | 628/1039 [00:42<00:27, 15.07it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  61%|██████    | 630/1039 [00:42<00:28, 14.38it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  61%|██████    | 632/1039 [00:42<00:28, 14.16it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  63%|██████▎   | 654/1039 [00:43<00:24, 15.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  63%|██████▎   | 656/1039 [00:43<00:25, 15.20it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  66%|██████▌   | 686/1039 [00:45<00:25, 14.08it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  66%|██████▌   | 688/1039 [00:46<00:24, 14.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  69%|██████▉   | 720/1039 [00:48<00:21, 14.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  69%|██████▉   | 722/1039 [00:48<00:22, 14.02it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  70%|██████▉   | 724/1039 [00:48<00:22, 14.00it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  71%|███████   | 740/1039 [00:49<00:20, 14.63it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  71%|███████▏  | 742/1039 [00:49<00:21, 13.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  72%|███████▏  | 746/1039 [00:50<00:22, 13.06it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 780/1039 [00:52<00:18, 14.18it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 782/1039 [00:52<00:18, 14.27it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 784/1039 [00:52<00:18, 13.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 786/1039 [00:52<00:18, 13.38it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 790/1039 [00:53<00:19, 12.98it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 792/1039 [00:53<00:19, 12.87it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▋  | 794/1039 [00:53<00:20, 12.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  77%|███████▋  | 804/1039 [00:54<00:17, 13.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  78%|███████▊  | 806/1039 [00:54<00:17, 13.21it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  78%|███████▊  | 810/1039 [00:54<00:16, 13.90it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  79%|███████▉  | 824/1039 [00:55<00:13, 15.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 976/1039 [01:05<00:03, 16.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 978/1039 [01:05<00:03, 15.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 980/1039 [01:05<00:03, 15.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  96%|█████████▌| 1000/1039 [01:06<00:02, 16.16it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  96%|█████████▋| 1002/1039 [01:06<00:02, 14.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 1039/1039 [01:09<00:00, 15.03it/s]\n",
      "Encoding samples:   0%|          | 0/261 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   2%|▏         | 4/261 [00:00<00:15, 16.31it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   5%|▌         | 14/261 [00:00<00:16, 15.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:   6%|▌         | 16/261 [00:01<00:16, 15.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  18%|█▊        | 46/261 [00:02<00:13, 16.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  18%|█▊        | 48/261 [00:02<00:13, 16.27it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  19%|█▉        | 50/261 [00:03<00:13, 16.03it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  25%|██▍       | 64/261 [00:03<00:11, 16.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  25%|██▌       | 66/261 [00:04<00:12, 16.01it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  31%|███       | 80/261 [00:04<00:11, 15.82it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  47%|████▋     | 122/261 [00:07<00:08, 15.76it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  50%|████▉     | 130/261 [00:08<00:07, 16.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  59%|█████▉    | 154/261 [00:09<00:06, 16.00it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  63%|██████▎   | 164/261 [00:10<00:05, 16.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  64%|██████▍   | 168/261 [00:10<00:06, 15.30it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  67%|██████▋   | 176/261 [00:10<00:05, 16.17it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  68%|██████▊   | 178/261 [00:11<00:05, 15.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  69%|██████▉   | 180/261 [00:11<00:05, 15.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  71%|███████▏  | 186/261 [00:11<00:04, 15.65it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  75%|███████▌  | 196/261 [00:12<00:04, 16.03it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  76%|███████▌  | 198/261 [00:12<00:04, 15.61it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  77%|███████▋  | 202/261 [00:12<00:03, 15.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  78%|███████▊  | 204/261 [00:12<00:03, 15.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  80%|███████▉  | 208/261 [00:13<00:03, 15.34it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  93%|█████████▎| 242/261 [00:15<00:01, 17.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  95%|█████████▌| 248/261 [00:15<00:00, 16.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 261/261 [00:16<00:00, 15.97it/s]\n",
      "Encoding samples:  65%|██████▌   | 953/1462 [01:00<00:30, 16.81it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 1462/1462 [01:33<00:00, 15.65it/s]\n",
      "Encoding samples:  61%|██████    | 224/367 [00:13<00:09, 14.36it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 367/367 [00:23<00:00, 15.47it/s]\n",
      "Encoding samples:  83%|████████▎ | 620/746 [00:39<00:07, 16.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 746/746 [00:47<00:00, 15.78it/s]\n",
      "Encoding samples: 100%|██████████| 187/187 [00:11<00:00, 15.73it/s]\n",
      "Encoding samples:  12%|█▏        | 49/420 [00:03<00:23, 16.05it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  71%|███████   | 297/420 [00:17<00:07, 16.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  87%|████████▋ | 365/420 [00:21<00:03, 17.66it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 420/420 [00:25<00:00, 16.65it/s]\n",
      "Encoding samples: 100%|██████████| 107/107 [00:06<00:00, 16.77it/s]\n",
      "Encoding samples: 100%|██████████| 291/291 [00:18<00:00, 15.65it/s]\n",
      "Encoding samples: 100%|██████████| 75/75 [00:04<00:00, 15.66it/s]\n",
      "Encoding samples: 100%|██████████| 252/252 [00:15<00:00, 15.78it/s]\n",
      "Encoding samples: 100%|██████████| 64/64 [00:03<00:00, 16.94it/s]\n",
      "Encoding samples:   0%|          | 0/272 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  77%|███████▋  | 210/272 [00:12<00:03, 16.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  78%|███████▊  | 212/272 [00:12<00:03, 16.27it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  79%|███████▊  | 214/272 [00:12<00:03, 16.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  93%|█████████▎| 254/272 [00:15<00:01, 14.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 256/272 [00:15<00:01, 13.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 272/272 [00:16<00:00, 16.11it/s]\n",
      "Encoding samples:  74%|███████▍  | 52/70 [00:03<00:01, 16.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  91%|█████████▏| 64/70 [00:03<00:00, 17.86it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples:  94%|█████████▍| 66/70 [00:03<00:00, 17.47it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Encoding samples: 100%|██████████| 70/70 [00:04<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ChemBERTa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepChem/ChemBERTa-77M-MTR were not used when initializing RobertaForRegression: ['norm_mean', 'norm_std']\n",
      "- This IS expected if you are initializing RobertaForRegression from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForRegression from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForRegression were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized because the shapes did not match:\n",
      "- regression.out_proj.weight: found shape torch.Size([199, 384]) in the checkpoint and torch.Size([1, 384]) in the model instantiated\n",
      "- regression.out_proj.bias: found shape torch.Size([199]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for model ChemBERTa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding samples: 100%|██████████| 263/263 [00:02<00:00, 91.65it/s] \n",
      "Encoding samples: 100%|██████████| 67/67 [00:00<00:00, 93.79it/s] \n",
      "Encoding samples: 100%|██████████| 412/412 [00:04<00:00, 87.55it/s] \n",
      "Encoding samples: 100%|██████████| 104/104 [00:01<00:00, 86.93it/s]\n",
      "Encoding samples: 100%|██████████| 1238/1238 [00:15<00:00, 81.08it/s]\n",
      "Encoding samples: 100%|██████████| 311/311 [00:03<00:00, 80.53it/s]\n",
      "Encoding samples: 100%|██████████| 1039/1039 [00:13<00:00, 78.93it/s]\n",
      "Encoding samples: 100%|██████████| 261/261 [00:03<00:00, 77.15it/s]\n",
      "Encoding samples: 100%|██████████| 1462/1462 [00:14<00:00, 102.95it/s]\n",
      "Encoding samples: 100%|██████████| 367/367 [00:03<00:00, 98.04it/s] \n",
      "Encoding samples: 100%|██████████| 746/746 [00:07<00:00, 94.41it/s] \n",
      "Encoding samples: 100%|██████████| 187/187 [00:01<00:00, 104.43it/s]\n",
      "Encoding samples: 100%|██████████| 420/420 [00:03<00:00, 105.31it/s]\n",
      "Encoding samples: 100%|██████████| 107/107 [00:00<00:00, 110.46it/s]\n",
      "Encoding samples: 100%|██████████| 291/291 [00:02<00:00, 103.44it/s]\n",
      "Encoding samples: 100%|██████████| 75/75 [00:00<00:00, 106.12it/s]\n",
      "Encoding samples: 100%|██████████| 252/252 [00:02<00:00, 87.77it/s]\n",
      "Encoding samples: 100%|██████████| 64/64 [00:00<00:00, 92.50it/s]\n",
      "Encoding samples: 100%|██████████| 272/272 [00:03<00:00, 86.21it/s]\n",
      "Encoding samples: 100%|██████████| 70/70 [00:00<00:00, 89.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model MolGPT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: number of parameters: 6.392832e+06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed key: prop_nn.weight from checkpoint; not found in model or size mismatch.\n",
      "Removed key: prop_nn.bias from checkpoint; not found in model or size mismatch.\n",
      "Computing embeddings for model MolGPT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering data: 100%|██████████| 525/525 [00:00<00:00, 94653.09it/s]\n",
      "WARNING: Filtered 809 examples due to unknown characters.\n",
      "  0%|          | 0/263 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 263/263 [00:08<00:00, 30.76it/s]\n",
      "Filtering data: 100%|██████████| 134/134 [00:00<00:00, 62441.59it/s]\n",
      "WARNING: Filtered 190 examples due to unknown characters.\n",
      "  0%|          | 0/67 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 67/67 [00:02<00:00, 26.85it/s]\n",
      "Filtering data: 100%|██████████| 823/823 [00:00<00:00, 47124.44it/s]\n",
      "WARNING: Filtered 442 examples due to unknown characters.\n",
      "  0%|          | 0/412 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 99%|█████████▉| 409/412 [00:12<00:00, 30.48it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 412/412 [00:13<00:00, 31.51it/s]\n",
      "Filtering data: 100%|██████████| 208/208 [00:00<00:00, 71310.71it/s]\n",
      "WARNING: Filtered 110 examples due to unknown characters.\n",
      "  0%|          | 0/104 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 104/104 [00:03<00:00, 29.51it/s]\n",
      "Filtering data: 100%|██████████| 2476/2476 [00:00<00:00, 75724.03it/s]\n",
      "WARNING: Filtered 1862 examples due to unknown characters.\n",
      "  0%|          | 0/1238 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1238/1238 [00:42<00:00, 29.44it/s]\n",
      "Filtering data: 100%|██████████| 621/621 [00:00<00:00, 59621.00it/s]\n",
      "WARNING: Filtered 472 examples due to unknown characters.\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 311/311 [00:11<00:00, 27.74it/s]\n",
      "Filtering data: 100%|██████████| 2077/2077 [00:00<00:00, 33179.22it/s]\n",
      "WARNING: Filtered 5760 examples due to unknown characters.\n",
      "  0%|          | 0/1039 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1039/1039 [00:31<00:00, 33.17it/s]\n",
      "Filtering data: 100%|██████████| 521/521 [00:00<00:00, 72385.05it/s]\n",
      "WARNING: Filtered 1497 examples due to unknown characters.\n",
      "  0%|          | 0/261 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 261/261 [00:08<00:00, 32.47it/s]\n",
      "Filtering data: 100%|██████████| 2924/2924 [00:00<00:00, 41352.31it/s]\n",
      "WARNING: Filtered 1872 examples due to unknown characters.\n",
      "  0%|          | 0/1462 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1462/1462 [00:44<00:00, 32.78it/s]\n",
      "Filtering data: 100%|██████████| 733/733 [00:00<00:00, 85657.66it/s]\n",
      "WARNING: Filtered 451 examples due to unknown characters.\n",
      "  0%|          | 0/367 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 367/367 [00:11<00:00, 31.50it/s]\n",
      "Filtering data: 100%|██████████| 1491/1491 [00:00<00:00, 39006.93it/s]\n",
      "WARNING: Filtered 311 examples due to unknown characters.\n",
      "  0%|          | 0/746 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 746/746 [00:29<00:00, 25.10it/s]\n",
      "Filtering data: 100%|██████████| 374/374 [00:00<00:00, 109414.08it/s]\n",
      "WARNING: Filtered 116 examples due to unknown characters.\n",
      "  0%|          | 0/187 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 187/187 [00:07<00:00, 24.33it/s]\n",
      "Filtering data: 100%|██████████| 839/839 [00:00<00:00, 47872.63it/s]\n",
      "WARNING: Filtered 840 examples due to unknown characters.\n",
      "  0%|          | 0/420 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 420/420 [00:16<00:00, 25.00it/s]\n",
      "Filtering data: 100%|██████████| 213/213 [00:00<00:00, 102818.13it/s]\n",
      "WARNING: Filtered 203 examples due to unknown characters.\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 107/107 [00:04<00:00, 24.24it/s]\n",
      "Filtering data: 100%|██████████| 582/582 [00:00<00:00, 63495.51it/s]\n",
      "  0%|          | 0/291 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 291/291 [00:14<00:00, 20.60it/s]\n",
      "Filtering data: 100%|██████████| 149/149 [00:00<00:00, 63241.38it/s]\n",
      "  0%|          | 0/75 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 75/75 [00:04<00:00, 16.49it/s]\n",
      "Filtering data: 100%|██████████| 503/503 [00:00<00:00, 63553.89it/s]\n",
      "WARNING: Filtered 1304 examples due to unknown characters.\n",
      "  0%|          | 0/252 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 252/252 [00:09<00:00, 25.89it/s]\n",
      "Filtering data: 100%|██████████| 128/128 [00:00<00:00, 50467.28it/s]\n",
      "WARNING: Filtered 332 examples due to unknown characters.\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 64/64 [00:02<00:00, 23.22it/s]\n",
      "Filtering data: 100%|██████████| 543/543 [00:00<00:00, 23753.97it/s]\n",
      "WARNING: Filtered 1035 examples due to unknown characters.\n",
      "  0%|          | 0/272 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 272/272 [00:10<00:00, 25.38it/s]\n",
      "Filtering data: 100%|██████████| 139/139 [00:00<00:00, 61485.79it/s]\n",
      "WARNING: Filtered 262 examples due to unknown characters.\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 70/70 [00:03<00:00, 23.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model MoLeR...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.training.tracking'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_alias \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChemBERTa\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[43msmiles_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_configs_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_alias\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath_to_model_checkpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         smiles_model\u001b[38;5;241m.\u001b[39mload_pretrained(model_configs_dict[model_alias][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_model_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m], map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/app/code/jointformer/jointformer/models/moler.py:55\u001b[0m, in \u001b[0;36mMoler.load_pretrained\u001b[0;34m(self, filename, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pretrained\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_vae_model_and_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model, MoLeRVae), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/molecule_generation/utils/model_utils.py:23\u001b[0m, in \u001b[0;36mload_vae_model_and_dataset\u001b[0;34m(trained_model_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m trained_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m     19\u001b[0m     trained_model_path\n\u001b[1;32m     20\u001b[0m )  \u001b[38;5;66;03m# get_model_file_path takes `str` as input, so we need to cast it\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(get_model_file_path(trained_model_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpkl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m in_file:\n\u001b[0;32m---> 23\u001b[0m     data_to_load \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m atom_type_featuriser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m     26\u001b[0m     featuriser\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m featuriser \u001b[38;5;129;01min\u001b[39;00m data_to_load[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_extractors\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m featuriser\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAtomType\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m dummy_dataset \u001b[38;5;241m=\u001b[39m InMemoryTraceDataset(\n\u001b[1;32m     32\u001b[0m     params\u001b[38;5;241m=\u001b[39mdata_to_load[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_params\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     33\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mdata_to_load[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     MoLeR_style_traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28missubclass\u001b[39m(data_to_load[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_class\u001b[39m\u001b[38;5;124m\"\u001b[39m], MoLeRVae),\n\u001b[1;32m     38\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.training.tracking'"
     ]
    }
   ],
   "source": [
    "# Initialize results \n",
    "results = {\n",
    "    \"dataset\": [],\n",
    "    \"model\": [],\n",
    "    \"test_rmse\": [],\n",
    "    \"test_cliff_rmse\": [],\n",
    "}\n",
    "\n",
    "for model_alias in model_configs_dict.keys():\n",
    "    print(f\"Loading model {model_alias}...\")\n",
    "    \n",
    "    # Get tokenizer if needed\n",
    "    if model_configs_dict[model_alias][\"path_to_tokenizer\"] is not None:\n",
    "        tokenizer_config = TokenizerConfig.from_config_file(model_configs_dict[model_alias][\"path_to_tokenizer\"])\n",
    "        if model_alias == \"Jointformer\":\n",
    "            tokenizer_config.path_to_vocabulary = model_configs_dict[model_alias][\"path_to_vocab\"]\n",
    "        tokenizer = AutoTokenizer.from_config(tokenizer_config)\n",
    "    else:\n",
    "        tokenizer = None\n",
    "    \n",
    "    # Get model\n",
    "    model_config = ModelConfig.from_config_file(model_configs_dict[model_alias][\"path_to_model_config\"])\n",
    "    smiles_model = AutoModel.from_config(model_config)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Load model checkpoint on cpu\n",
    "    smiles_model.eval()\n",
    "    smiles_model.to(device)    \n",
    "\n",
    "    if model_alias != \"ChemBERTa\":\n",
    "        try:\n",
    "            smiles_model.load_pretrained(model_configs_dict[model_alias][\"path_to_model_checkpoint\"])\n",
    "        except RuntimeError:\n",
    "            smiles_model.load_pretrained(model_configs_dict[model_alias][\"path_to_model_checkpoint\"], map_location='cpu')\n",
    "\n",
    "    # Get embeddings\n",
    "    print(f\"Computing embeddings for model {model_alias}...\")\n",
    "\n",
    "    smiles_encoder = smiles_model.to_smiles_encoder(tokenizer, batch_size=2, device=\"cpu\")\n",
    "\n",
    "    # Iterate over all datasets\n",
    "    for dataset in datasets_list_df[\"Dataset\"].unique()[:10]:\n",
    "        # Load data\n",
    "        raw_data = Data(dataset)\n",
    "\n",
    "        # Compute embeddings\n",
    "        X_train_jointformer_embeddings = smiles_encoder.encode(raw_data.smiles_train)\n",
    "\n",
    "        X_test_jointformer_embeddings = smiles_encoder.encode(raw_data.smiles_test)\n",
    "\n",
    "        ### Model with svm and jointformer embeddings\n",
    "        model = SVR(kernel=\"rbf\")\n",
    "\n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(model, per_model_hyperparameters_grid[\"svm\"], scoring=\"neg_mean_squared_error\", n_jobs=2, cv=5)\n",
    "        grid_search.fit(X_train_jointformer_embeddings, raw_data.y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = grid_search.best_estimator_.predict(X_test_jointformer_embeddings)\n",
    "        test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "        test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "        results[\"dataset\"].append(dataset)\n",
    "        results[\"model\"].append(f\"svm_{model_alias}\")\n",
    "        results[\"test_rmse\"].append(test_rmse)\n",
    "        results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "        ### Model with knn and jointformer embeddings\n",
    "        model = KNeighborsRegressor()\n",
    "\n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(model, per_model_hyperparameters_grid[\"knn\"], scoring=\"neg_mean_squared_error\", n_jobs=2, cv=5)\n",
    "        grid_search.fit(X_train_jointformer_embeddings, raw_data.y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = grid_search.best_estimator_.predict(X_test_jointformer_embeddings)\n",
    "        test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "        test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "        results[\"dataset\"].append(dataset)\n",
    "        results[\"model\"].append(f\"knn_{model_alias}\")\n",
    "        results[\"test_rmse\"].append(test_rmse)\n",
    "        results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "\n",
    "# Iterate over all datasets\n",
    "for dataset in datasets_list_df[\"Dataset\"].unique()[:10]:\n",
    "    ### Model from the MoleculeACE package - SVM with ECFP fingerprints\n",
    "    algorithm = MoleculeACE_SVM\n",
    "\n",
    "    # Get a featurizer\n",
    "    descriptor = Descriptors.ECFP\n",
    "    # Featurize the data\n",
    "    raw_data(descriptor)\n",
    "\n",
    "    # Get the already optimized hyperparameters\n",
    "    hyperparameters = get_benchmark_config(dataset, algorithm, descriptor)\n",
    "\n",
    "    # Train and evaluate\n",
    "    model = algorithm(**hyperparameters)\n",
    "    model.train(raw_data.x_train, raw_data.y_train)\n",
    "    y_pred = model.predict(raw_data.x_test)\n",
    "\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"svm_ecfp\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "    ### Model from the MoleculeACE package - KNN with ECFP fingerprints\n",
    "    algorithm = MoleculeACE_KNN\n",
    "\n",
    "    # Get a featurizer\n",
    "    descriptor = Descriptors.ECFP\n",
    "    # Featurize the data\n",
    "    raw_data(descriptor)\n",
    "\n",
    "    # Get the already optimized hyperparameters\n",
    "    hyperparameters = get_benchmark_config(dataset, algorithm, descriptor)\n",
    "\n",
    "    # Train and evaluate\n",
    "    model = algorithm(**hyperparameters)\n",
    "    model.train(raw_data.x_train, raw_data.y_train)\n",
    "    y_pred = model.predict(raw_data.x_test)\n",
    "\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"knn_ecfp\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "results_copy = copy.deepcopy(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all datasets\n",
    "for dataset in datasets_list_df[\"Dataset\"].unique()[:10]:\n",
    "    ### Model from the MoleculeACE package - SVM with ECFP fingerprints\n",
    "    algorithm = MoleculeACE_SVM\n",
    "\n",
    "    # Get a featurizer\n",
    "    descriptor = Descriptors.ECFP\n",
    "    # Featurize the data\n",
    "    raw_data(descriptor)\n",
    "\n",
    "    # Get the already optimized hyperparameters\n",
    "    hyperparameters = get_benchmark_config(dataset, algorithm, descriptor)\n",
    "\n",
    "    # Train and evaluate\n",
    "    model = algorithm(**hyperparameters)\n",
    "    model.train(raw_data.x_train, raw_data.y_train)\n",
    "    y_pred = model.predict(raw_data.x_test)\n",
    "\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"svm_ecfp\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "    ### Model from the MoleculeACE package - KNN with ECFP fingerprints\n",
    "    algorithm = MoleculeACE_KNN\n",
    "\n",
    "    # Get a featurizer\n",
    "    descriptor = Descriptors.ECFP\n",
    "    # Featurize the data\n",
    "    raw_data(descriptor)\n",
    "\n",
    "    # Get the already optimized hyperparameters\n",
    "    hyperparameters = get_benchmark_config(dataset, algorithm, descriptor)\n",
    "\n",
    "    # Train and evaluate\n",
    "    model = algorithm(**hyperparameters)\n",
    "    model.train(raw_data.x_train, raw_data.y_train)\n",
    "    y_pred = model.predict(raw_data.x_test)\n",
    "\n",
    "    test_rmse = calc_rmse(raw_data.y_test, y_pred)\n",
    "    test_cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=raw_data.y_test, cliff_mols_test=raw_data.cliff_mols_test)\n",
    "\n",
    "    results[\"dataset\"].append(dataset)\n",
    "    results[\"model\"].append(\"knn_ecfp\")\n",
    "    results[\"test_rmse\"].append(test_rmse)\n",
    "    results[\"test_cliff_rmse\"].append(test_cliff_rmse)\n",
    "\n",
    "    results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv(\"cliffs_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_cliff_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CHEMBL218_EC50</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CHEMBL244_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CHEMBL236_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CHEMBL234_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>CHEMBL219_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>CHEMBL238_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>CHEMBL4203_Ki</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CHEMBL2047_EC50</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CHEMBL4616_EC50</td>\n",
       "      <td>svm_ecfp</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.69243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset     model  test_rmse  test_cliff_rmse\n",
       "60    CHEMBL1871_Ki  svm_ecfp   0.635268          0.69243\n",
       "62   CHEMBL218_EC50  svm_ecfp   0.635268          0.69243\n",
       "64     CHEMBL244_Ki  svm_ecfp   0.635268          0.69243\n",
       "66     CHEMBL236_Ki  svm_ecfp   0.635268          0.69243\n",
       "68     CHEMBL234_Ki  svm_ecfp   0.635268          0.69243\n",
       "70     CHEMBL219_Ki  svm_ecfp   0.635268          0.69243\n",
       "72     CHEMBL238_Ki  svm_ecfp   0.635268          0.69243\n",
       "74    CHEMBL4203_Ki  svm_ecfp   0.635268          0.69243\n",
       "76  CHEMBL2047_EC50  svm_ecfp   0.635268          0.69243\n",
       "78  CHEMBL4616_EC50  svm_ecfp   0.635268          0.69243"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"model\"] == \"svm_ecfp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_cliff_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>svm_Jointformer</td>\n",
       "      <td>0.751870</td>\n",
       "      <td>0.972532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL1871_Ki</td>\n",
       "      <td>knn_Jointformer</td>\n",
       "      <td>0.782974</td>\n",
       "      <td>1.005236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL218_EC50</td>\n",
       "      <td>svm_Jointformer</td>\n",
       "      <td>0.831831</td>\n",
       "      <td>0.873431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL218_EC50</td>\n",
       "      <td>knn_Jointformer</td>\n",
       "      <td>0.933281</td>\n",
       "      <td>0.926280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL244_Ki</td>\n",
       "      <td>svm_Jointformer</td>\n",
       "      <td>0.998222</td>\n",
       "      <td>1.004544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset            model  test_rmse  test_cliff_rmse\n",
       "0   CHEMBL1871_Ki  svm_Jointformer   0.751870         0.972532\n",
       "1   CHEMBL1871_Ki  knn_Jointformer   0.782974         1.005236\n",
       "2  CHEMBL218_EC50  svm_Jointformer   0.831831         0.873431\n",
       "3  CHEMBL218_EC50  knn_Jointformer   0.933281         0.926280\n",
       "4    CHEMBL244_Ki  svm_Jointformer   0.998222         1.004544"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load results\n",
    "results_df = pd.read_csv(\"cliffs_results.csv\")\n",
    "\n",
    "print(results_df.shape)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_rmse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_cliff_rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn_ChemBERTa</th>\n",
       "      <td>0.876673</td>\n",
       "      <td>0.102729</td>\n",
       "      <td>0.911365</td>\n",
       "      <td>0.137953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_Jointformer</th>\n",
       "      <td>0.942033</td>\n",
       "      <td>0.127061</td>\n",
       "      <td>0.943374</td>\n",
       "      <td>0.154292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_MolGPT</th>\n",
       "      <td>0.914833</td>\n",
       "      <td>0.088401</td>\n",
       "      <td>0.965634</td>\n",
       "      <td>0.146896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_ecfp</th>\n",
       "      <td>0.734557</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.826023</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_ChemBERTa</th>\n",
       "      <td>0.814152</td>\n",
       "      <td>0.107163</td>\n",
       "      <td>0.902135</td>\n",
       "      <td>0.201192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_Jointformer</th>\n",
       "      <td>0.848662</td>\n",
       "      <td>0.104998</td>\n",
       "      <td>0.910169</td>\n",
       "      <td>0.162760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_MolGPT</th>\n",
       "      <td>0.790100</td>\n",
       "      <td>0.091727</td>\n",
       "      <td>0.873872</td>\n",
       "      <td>0.172224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_ecfp</th>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                test_rmse           test_cliff_rmse          \n",
       "                     mean       std            mean       std\n",
       "model                                                        \n",
       "knn_ChemBERTa    0.876673  0.102729        0.911365  0.137953\n",
       "knn_Jointformer  0.942033  0.127061        0.943374  0.154292\n",
       "knn_MolGPT       0.914833  0.088401        0.965634  0.146896\n",
       "knn_ecfp         0.734557  0.002506        0.826023  0.000802\n",
       "svm_ChemBERTa    0.814152  0.107163        0.902135  0.201192\n",
       "svm_Jointformer  0.848662  0.104998        0.910169  0.162760\n",
       "svm_MolGPT       0.790100  0.091727        0.873872  0.172224\n",
       "svm_ecfp         0.635268  0.000000        0.692430  0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate results over models\n",
    "results_agg_df = results_df.groupby(\"model\").agg({\n",
    "    \"test_rmse\": [\"mean\", \"std\"],\n",
    "    \"test_cliff_rmse\": [\"mean\", \"std\"],\n",
    "})\n",
    "results_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{test\\_rmse} & \\multicolumn{2}{l}{test\\_cliff\\_rmse} \\\\\n",
      "{} &      mean &       std &            mean &       std \\\\\n",
      "model           &           &           &                 &           \\\\\n",
      "\\midrule\n",
      "svm\\_ecfp        &  0.635268 &  0.000000 &        0.692430 &  0.000000 \\\\\n",
      "knn\\_ecfp        &  0.734557 &  0.002506 &        0.826023 &  0.000802 \\\\\n",
      "svm\\_MolGPT      &  0.790100 &  0.091727 &        0.873872 &  0.172224 \\\\\n",
      "svm\\_ChemBERTa   &  0.814152 &  0.107163 &        0.902135 &  0.201192 \\\\\n",
      "svm\\_Jointformer &  0.848662 &  0.104998 &        0.910169 &  0.162760 \\\\\n",
      "knn\\_ChemBERTa   &  0.876673 &  0.102729 &        0.911365 &  0.137953 \\\\\n",
      "knn\\_Jointformer &  0.942033 &  0.127061 &        0.943374 &  0.154292 \\\\\n",
      "knn\\_MolGPT      &  0.914833 &  0.088401 &        0.965634 &  0.146896 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23794/4121289481.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_agg_df.sort_values((\"test_cliff_rmse\", \"mean\")).to_latex())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_rmse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_cliff_rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm_ecfp</th>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_ecfp</th>\n",
       "      <td>0.734557</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.826023</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_MolGPT</th>\n",
       "      <td>0.790100</td>\n",
       "      <td>0.091727</td>\n",
       "      <td>0.873872</td>\n",
       "      <td>0.172224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_ChemBERTa</th>\n",
       "      <td>0.814152</td>\n",
       "      <td>0.107163</td>\n",
       "      <td>0.902135</td>\n",
       "      <td>0.201192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_Jointformer</th>\n",
       "      <td>0.848662</td>\n",
       "      <td>0.104998</td>\n",
       "      <td>0.910169</td>\n",
       "      <td>0.162760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_ChemBERTa</th>\n",
       "      <td>0.876673</td>\n",
       "      <td>0.102729</td>\n",
       "      <td>0.911365</td>\n",
       "      <td>0.137953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_Jointformer</th>\n",
       "      <td>0.942033</td>\n",
       "      <td>0.127061</td>\n",
       "      <td>0.943374</td>\n",
       "      <td>0.154292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_MolGPT</th>\n",
       "      <td>0.914833</td>\n",
       "      <td>0.088401</td>\n",
       "      <td>0.965634</td>\n",
       "      <td>0.146896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                test_rmse           test_cliff_rmse          \n",
       "                     mean       std            mean       std\n",
       "model                                                        \n",
       "svm_ecfp         0.635268  0.000000        0.692430  0.000000\n",
       "knn_ecfp         0.734557  0.002506        0.826023  0.000802\n",
       "svm_MolGPT       0.790100  0.091727        0.873872  0.172224\n",
       "svm_ChemBERTa    0.814152  0.107163        0.902135  0.201192\n",
       "svm_Jointformer  0.848662  0.104998        0.910169  0.162760\n",
       "knn_ChemBERTa    0.876673  0.102729        0.911365  0.137953\n",
       "knn_Jointformer  0.942033  0.127061        0.943374  0.154292\n",
       "knn_MolGPT       0.914833  0.088401        0.965634  0.146896"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by test cliff rmse\n",
    "print(results_agg_df.sort_values((\"test_cliff_rmse\", \"mean\")).to_latex())\n",
    "results_agg_df.sort_values((\"test_cliff_rmse\", \"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23794/3503739359.py:23: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=90)\n",
      "/tmp/ipykernel_23794/3503739359.py:32: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=90)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot of the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Define your custom palette\n",
    "# p = {\n",
    "#     \"svm_jointformer\": \"skyblue\",\n",
    "#     \"knn_jointformer\": \"skyblue\",\n",
    "#     \"svm_ecfp\": \"lightcoral\",\n",
    "#     \"knn_ecfp\": \"lightcoral\",\n",
    "\n",
    "# }\n",
    "\n",
    "sns.boxplot(data=results_df[~results_df[\"model\"].str.contains(\"ecfp\")], x=\"model\", y=\"test_rmse\", ax=ax[0])\n",
    "ax[0].set_title(\"Bioactivity prediction RMSE - all\")\n",
    "ax[0].set_ylabel(\"Test RMSE\")\n",
    "ax[0].set_xlabel(\"Model\")\n",
    "# Same scale on y-axis\n",
    "ax[0].set_ylim(0, 2)\n",
    "# Rotate x-axis tick labels\n",
    "ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=90)\n",
    "\n",
    "sns.boxplot(data=results_df[~results_df[\"model\"].str.contains(\"ecfp\")], x=\"model\", y=\"test_cliff_rmse\", ax=ax[1])\n",
    "ax[1].set_title(\"Bioactivity prediction RMSE - activity cliffs\")\n",
    "ax[1].set_ylabel(\"Test cliff RMSE\")\n",
    "ax[1].set_xlabel(\"Model\")\n",
    "# Same scale on y-axis\n",
    "ax[1].set_ylim(0, 1.5)\n",
    "# Rotate x-axis tick labels\n",
    "ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cliffs_results.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
